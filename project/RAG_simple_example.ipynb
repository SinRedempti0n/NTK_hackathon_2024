{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZX--sgAOA-CU",
      "metadata": {
        "id": "ZX--sgAOA-CU"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu transformers sentence-transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "42972321-36a6-44d6-88e5-aa69af25528a",
      "metadata": {
        "id": "42972321-36a6-44d6-88e5-aa69af25528a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Any, List, Mapping, Optional\n",
        "\n",
        "import langchain\n",
        "import langchain.document_loaders\n",
        "import pandas as pd\n",
        "import torch\n",
        "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain, chains, prompts\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.document_transformers import LongContextReorder\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.language_models.llms import LLM\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EF1q73PlIJ7N",
      "metadata": {
        "id": "EF1q73PlIJ7N"
      },
      "source": [
        "## Полезные ресурсы"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tOlwmmToIO6w",
      "metadata": {
        "id": "tOlwmmToIO6w"
      },
      "source": [
        "1. https://habr.com/ru/articles/779526/ - что вообще делаем\n",
        "2. https://habr.com/ru/articles/599673/ - что такое GPT, как работает. Вам особенно пригодится пункт с файнтьюнингом\n",
        "3. https://python.langchain.com/docs/get_started/introduction - основной фреймворк для создания RAG\n",
        "4. https://www.llamaindex.ai/ - тоже фреймворк с похожим функционалом, может пригодиться, если langchain не покроет потребности все\n",
        "5. https://huggingface.co/ - сайт с моделями"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad985d2-c32b-44c2-a0c2-937f5ff61825",
      "metadata": {
        "id": "3ad985d2-c32b-44c2-a0c2-937f5ff61825"
      },
      "source": [
        "### Загрузка документов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "woumKvcoEEUw",
      "metadata": {
        "id": "woumKvcoEEUw"
      },
      "source": [
        "В данной ячейке загружается база знаний. Сейчас тут текст, скопированный из википедии по астра линуксу. Тут могут быть документы в формате docx, pptx, pdf, pandas dataframe и так далее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "15078e7c-e4cb-416d-8a29-c1d3d92e067f",
      "metadata": {
        "id": "15078e7c-e4cb-416d-8a29-c1d3d92e067f"
      },
      "outputs": [],
      "source": [
        "text = TextLoader(\"/content/astra_wiki.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d45d158-e765-4f7f-8bac-40c5e7db965c",
      "metadata": {
        "id": "0d45d158-e765-4f7f-8bac-40c5e7db965c"
      },
      "source": [
        "### Разбиваем документы на части"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "440266fc-1015-49dd-8314-0d951bae67a1",
      "metadata": {
        "id": "440266fc-1015-49dd-8314-0d951bae67a1"
      },
      "outputs": [],
      "source": [
        "documents = text.load()\n",
        "documents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e99fafb9-046f-4e96-88c3-5b3f107db02a",
      "metadata": {
        "id": "e99fafb9-046f-4e96-88c3-5b3f107db02a"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=200)  # у langchain есть много способов разбить документы на чанки, можете изучить другие и подобрать оптимальный\n",
        "texts = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc07e25a-e415-4a1a-91fe-ec9c9702b746",
      "metadata": {
        "id": "cc07e25a-e415-4a1a-91fe-ec9c9702b746"
      },
      "source": [
        "### Вычисляем эмбеддинги для всех фрагментов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ad99ff85-9349-48b9-8400-77b4b2f91fae",
      "metadata": {
        "id": "ad99ff85-9349-48b9-8400-77b4b2f91fae"
      },
      "outputs": [],
      "source": [
        "EMBEDDER_PATH = \"intfloat/multilingual-e5-small\"  # путь до модели эмбеддера, на huggingface можете подобрать другой, есть различные статьи по сравнению эмбеддеров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a2dda70-c1cb-4e16-a3a2-507723a394e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a2dda70-c1cb-4e16-a3a2-507723a394e1",
        "outputId": "3c8f57d2-903f-4289-9703-0a69c951c510"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDER_PATH\n",
        ")\n",
        "\n",
        "sample_vec = embeddings.embed_query(\"Hello, world!\")\n",
        "len(sample_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e12d8abe-22f9-4c73-9a77-04e50822f2bf",
      "metadata": {
        "id": "e12d8abe-22f9-4c73-9a77-04e50822f2bf"
      },
      "source": [
        "### Cохраняем эмбеддинги в векторную БД"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "732495c6-439c-412d-b551-cae6d0a1dac9",
      "metadata": {
        "id": "732495c6-439c-412d-b551-cae6d0a1dac9"
      },
      "outputs": [],
      "source": [
        "# создаем хранилище\n",
        "db = FAISS.from_documents(texts, embeddings)  # faiss - одна из наиболее популярных векторных БД, можете заменить на любую другую доступную\n",
        "db.as_retriever()\n",
        "\n",
        "# также можно сохранить хранилище локально\n",
        "db.save_local('faiss_index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8d5974e8-7262-422f-9d51-98aed1605afd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d5974e8-7262-422f-9d51-98aed1605afd",
        "outputId": "6e1a58fd-7abf-4745-ca60-40be8048ca85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(Document(page_content='Common Edition — единственная российская ОС, репозиторий которой размещен в открытом доступе международной некоммерческой организации The Linux Foundation;\\nSpecial Edition — сертифицированная ОС со встроенными средствами защиты информации (СЗИ) для стабильных и безопасных ИТ-инфраструктур любого масштаба и бесперебойной работы с данными любой степени конфиденциальности, лицензируется по трем уровням защиты.', metadata={'source': '/content/astra_wiki.txt'}),\n",
              "  0.30254525),\n",
              " (Document(page_content='Применение', metadata={'source': '/content/astra_wiki.txt'}),\n",
              "  0.32562894),\n",
              " (Document(page_content='Особенности версии Special Edition\\nРежимы защищенности\\nС релиза 2021 года (1.7/4.7) в Astra Linux Special Edition доступны режимы защищенности «Базовый» («Орел», несертифицированная версия), «Усиленный» («Воронеж») и «Максимальный» («Смоленск»). Режим «Усиленный» имеет все возможности режима «Базовый» и дополняет их, режим «Максимальный» имеет все возможности режима «Усиленный» и также дополняет их.', metadata={'source': '/content/astra_wiki.txt'}),\n",
              "  0.34284586),\n",
              " (Document(page_content='Основные версии\\n Внешние видеофайлы\\n\\tЛоготип YouTube Универсальная операционная система Astra Linux\\n\\nAstra Linux Special Edition в Национальном центре управления обороной РФ\\nПроизводителем разрабатывается версия Astra Linux Special Edition (специального назначения) и несертифицированная версия Common Edition (общего назначения):', metadata={'source': '/content/astra_wiki.txt'}),\n",
              "  0.376471)]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# тестируем ретривер\n",
        "q = \"Special Edition\"  #  запрос, который ищем в векторной базе данных\n",
        "db.similarity_search_with_score(q)  #  результат поиска и значение близости между запросом и документами в БД"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "85ec93b5-cdb5-4f73-bf55-2fa915b5beca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85ec93b5-cdb5-4f73-bf55-2fa915b5beca",
        "outputId": "3b30efe7-539e-4788-a16c-ebe455b46ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Common Edition — единственная российская ОС, репозиторий которой размещен в открытом доступе международной некоммерческой организации The Linux Foundation;\n",
            "Special Edition — сертифицированная ОС со встроенными средствами защиты информации (СЗИ) для стабильных и безопасных ИТ-инфраструктур любого масштаба и бесперебойной работы с данными любой степени конфиденциальности, лицензируется по трем уровням защиты.\n",
            "**************************************************\n",
            "Применение\n",
            "**************************************************\n",
            "Особенности версии Special Edition\n",
            "Режимы защищенности\n",
            "С релиза 2021 года (1.7/4.7) в Astra Linux Special Edition доступны режимы защищенности «Базовый» («Орел», несертифицированная версия), «Усиленный» («Воронеж») и «Максимальный» («Смоленск»). Режим «Усиленный» имеет все возможности режима «Базовый» и дополняет их, режим «Максимальный» имеет все возможности режима «Усиленный» и также дополняет их.\n",
            "**************************************************\n",
            "Основные версии\n",
            " Внешние видеофайлы\n",
            "\tЛоготип YouTube Универсальная операционная система Astra Linux\n",
            "\n",
            "Astra Linux Special Edition в Национальном центре управления обороной РФ\n",
            "Производителем разрабатывается версия Astra Linux Special Edition (специального назначения) и несертифицированная версия Common Edition (общего назначения):\n",
            "**************************************************\n",
            "Мандатный контроль целостности и замкнутая программная среда\n",
            "**************************************************\n"
          ]
        }
      ],
      "source": [
        "retriever = db.as_retriever(search_kwargs={\"k\": 5})  # поиск К наиболее похожих документов на запрос\n",
        "res = retriever.get_relevant_documents(q)\n",
        "for x in res:\n",
        "    print(x.page_content)\n",
        "    print(\"*\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0a248bf-f4a0-4c94-bfe0-88373059db1a",
      "metadata": {
        "id": "b0a248bf-f4a0-4c94-bfe0-88373059db1a"
      },
      "source": [
        "### Подключаем Большую Языковую Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lZd0WTXWJy0Y",
      "metadata": {
        "id": "lZd0WTXWJy0Y"
      },
      "source": [
        "Посмотрите какие еще есть GPT модели в открытом доступе с небольшим кол-вом параметров (до 1 млрда, свыше 500 млн вряд ли поместится в collab)\n",
        "\n",
        "Помимо GPT моделей рекомендую рассмотреть архитектуру T5. В рамках кейса Вас будет интересовать способность модели отвечать на вопросы (QA answering). Пример: https://habr.com/ru/articles/581932/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c74cebff-89f5-441e-99ac-edbebad883e5",
      "metadata": {
        "id": "c74cebff-89f5-441e-99ac-edbebad883e5"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = r'ai-forever/rugpt3small_based_on_gpt2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)  # загружаем токенизатор модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "df8c2f8b-5cea-4707-8abc-37a700613712",
      "metadata": {
        "id": "df8c2f8b-5cea-4707-8abc-37a700613712"
      },
      "outputs": [],
      "source": [
        "class CustomLLM(LLM):\n",
        "    model: object\n",
        "    tokenizer: object\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom\"\n",
        "\n",
        "    def inference_llama(self, prompt: str):\n",
        "        # Encode the prompt and generate tokens\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", return_token_type_ids=False).to(device)\n",
        "        generated_ids = self.model.generate(**inputs, max_new_tokens=1024, num_beams=1, do_sample=False)\n",
        "        outputs = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "        return outputs[0]\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        **kwargs: Any,\n",
        "    ) -> str:\n",
        "\n",
        "        return self.inference_llama(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d514f5ea-f92e-46d1-bfc8-bf5f870ef89f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d514f5ea-f92e-46d1-bfc8-bf5f870ef89f",
        "outputId": "33ec8f86-26c2-4130-a6c9-63f17559436b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50264, 768)\n",
              "    (wpe): Embedding(2048, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50264, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map='auto')  #  загружаем выбранную модель\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # при исползовании GPU скорость работы значительно возрастает. Не рекомендую оставлять сессию с включенным GPU  в бездействии.\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2f5b9447-1ffc-4fa6-8ade-91233b58dbe1",
      "metadata": {
        "id": "2f5b9447-1ffc-4fa6-8ade-91233b58dbe1"
      },
      "outputs": [],
      "source": [
        "llm = CustomLLM(model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e2af4838-479a-45f7-8f61-3c0992075e95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "e2af4838-479a-45f7-8f61-3c0992075e95",
        "outputId": "af05476f-5681-4eb6-a2fe-dfaaedbe5e2e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Как звали Достоевского?\\nНиколай Васильевич Гоголь\\n\\n\\n\\n\\nНиколай Васильевич Гоголь\\n\\nКак звали Достоевского?\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(\"Как звали Достоевского?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2f52f53-0b80-44ec-a298-c764a2f34f36",
      "metadata": {
        "id": "f2f52f53-0b80-44ec-a298-c764a2f34f36"
      },
      "source": [
        "### Собираем Retrieval-Augmented Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qr5h-OpOKTGw",
      "metadata": {
        "id": "qr5h-OpOKTGw"
      },
      "source": [
        "В ячейке ниже предоставлен промпт для работы с большими языковыми моделями. Мы работали с моделью с 7 млрдами параметров. В Вашем кейсе, может быть, промпт нужно будет немного видоизменить в зависимости от модели, которую вы выберете."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9464adaa-6aa3-4afd-abda-5e7a9b6b2c5c",
      "metadata": {
        "id": "9464adaa-6aa3-4afd-abda-5e7a9b6b2c5c"
      },
      "outputs": [],
      "source": [
        "# Промпт для обработки документов\n",
        "document_prompt = langchain.prompts.PromptTemplate(\n",
        "    input_variables=[\"page_content\"], template=\"{page_content}\"\n",
        ")\n",
        "\n",
        "# Промпт для языковой модели\n",
        "document_variable_name = \"context\"\n",
        "stuff_prompt_override = \"\"\"\n",
        "Текст:\n",
        "-----\n",
        "{context}\n",
        "-----\n",
        "\n",
        "Пожалуйста, посмотри на текст выше и ответь на вопрос, используя информацию из этого текста.\n",
        "\n",
        "Вопрос:\n",
        "{query}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = prompts.PromptTemplate(\n",
        "    template=stuff_prompt_override, input_variables=[\"context\", \"query\"]\n",
        ")\n",
        "\n",
        "# Создаём цепочку\n",
        "llm_chain = chains.LLMChain(llm=llm, prompt=prompt)\n",
        "chain = chains.StuffDocumentsChain(\n",
        "    llm_chain=llm_chain,\n",
        "    document_prompt=document_prompt,\n",
        "    document_variable_name=document_variable_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "63d3bf13-90d8-4842-aeea-6fab75e99b81",
      "metadata": {
        "id": "63d3bf13-90d8-4842-aeea-6fab75e99b81"
      },
      "outputs": [],
      "source": [
        "QUESTION = \"Что такое Special Edition?\"  # Вопрос, на который мы хотим получить ответ\n",
        "NUMBER_OF_DOCS_TO_RETRIEVE = 5  # кол-во документов, которые мы хотим достать из векторной БД для ответа на вопрос"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "2d21edf8-5cb6-4d0a-8d8d-396129d97afd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d21edf8-5cb6-4d0a-8d8d-396129d97afd",
        "outputId": "9e950aa1-5dff-405e-a408-0270448040d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Edition?\n",
            "\n",
            "— Это когда ты читаешь книгу, а потом смотришь фильм.\n",
            "\n",
            "— А что такое Special Ed\n"
          ]
        }
      ],
      "source": [
        "print(llm(QUESTION))  # ответ модели без использования RAG (без контекста из базы знаний)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a342c181-5a8d-4870-a799-957284445555",
      "metadata": {
        "id": "a342c181-5a8d-4870-a799-957284445555"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(search_kwargs={\"k\": NUMBER_OF_DOCS_TO_RETRIEVE})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ca64ff37-5d0c-4edf-a270-940489aa7f56",
      "metadata": {
        "id": "ca64ff37-5d0c-4edf-a270-940489aa7f56"
      },
      "outputs": [],
      "source": [
        "reorderer = LongContextReorder()\n",
        "\n",
        "\n",
        "def answer(query, reorder=True, print_results=False):\n",
        "    results = retriever.get_relevant_documents(query)\n",
        "    if print_results:\n",
        "        for x in results:\n",
        "            print(f\"{x.page_content}\\n--------\")\n",
        "    if reorder:\n",
        "        results = reorderer.transform_documents(results)\n",
        "\n",
        "    generated_text = chain.run(input_documents=results, query=query).split(\"Ответ:\")[-1]\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "49af5b92-3426-40ed-9adf-3e3966fd21a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49af5b92-3426-40ed-9adf-3e3966fd21a3",
        "outputId": "92ad9e3f-ff4f-4c65-bdee-6dd9780d2b79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Это специальная версия, которая предназначена для использования в системах защиты информации, в том числе в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления доступом, в системах управления\n"
          ]
        }
      ],
      "source": [
        "gen_text = answer(QUESTION, print_results=False)  # Ответ модели с учетом используемого контекста. Обратите внимание на неспособность модели хорошо отвечать на вопрос. В этом поможет дообучение модели на предоставленных ранее данных (пары вопрос-ответ).\n",
        "print(str(gen_text))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python kernel vylegzhanin.ev",
      "language": "python",
      "name": "vylegzhanin.ev"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
